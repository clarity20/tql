# vim:filetype=sh:fdm=marker:

# Source the file of universal TQL constants. TODO Move more of the constants below into this file.
if ((g_sourcedGlobals!=1)); then
    source $TQL_HOME/tql_globals
    g_sourcedGlobals=1
fi

# Define certain types of tokens
declare -r g_ANDop='&&'
declare -r g_ORop='[|][|]'
declare -r g_leftParen='[[\({]'
declare -r g_rightParen='[]\)}]'

# Define a character sequence to delimit tokens in the internal token stream.
# This sequence may not appear unprotected in any token.
: ${tokenDelimiter:=$'\a'}

# Define a flag for single-character escapes
declare -r g_escapeChar='\\'

# Introduce some bookkeeping variables that allow us to accept un-protected spaces
# in string-type arguments so the user can enter hello world instead of hello" "world
# or "hello world". These variables are used in bufferToken() and streamToken().
g_compoundTokenType=
g_compoundTokenBuffer=

####################################################################################
# The parsing/lexing routine for query clauses and clause pieces
####################################################################################
function parseQueryClause()
{
    if [[ $# -gt 2 ]]; then
        echo Usage: $FUNCNAME clauseToBeParsed [isWhereClause]
        return 1
    fi

    local rhs=$1
    local isWhereClause=${2:-$FALSE}
    declare -i globalNestingLevel=0 funcNestingLevel=0
    declare -i NCVCount=0
    local output=""
    local letter="" previousLetter nextLetter
    local tokensInNCV="" currentNcvType currentSide
    declare -i wasLeftSideModulus=$FALSE

    # Preprocess the input string: clean up escape sequences and delimit the NCV subexpressions
    convertEscapeSequences "$rhs"; rhs=$g_returnString
    if ((isWhereClause)); then
        delimitNCVsInString "$rhs"; rhs=$g_returnString
    fi

    ################################################################################
    # Main processing loop: Pull tokens off the front of the input string one-by-one
    # and create a stream of token descriptors, tokens and some syntax annotations.
    # There are a few cases where we retroactively edit the stream as we discover new information from the input.
    ################################################################################

    while [[ -n $rhs ]]; do
        previousLetter=$letter
        letter=${rhs:0:1}
        nextLetter=${rhs:1:1}

        # Process NCV delimiter tokens that were added to the input stream during preprocessing
        if [[ $letter == $tokenDelimiter ]]; then
            case $nextLetter in
                ${tt[BEGIN_NCV]})
                    # Determine the NCV type and the expression side and begin counting tokens
                    [[ $rhs =~ ${tokenDelimiter}([${tt[END_NCV]}${tt[END_CV]}${tt[END_V]}]) ]]
                    currentNcvType=${BASH_REMATCH[1]}
                    if [[ "$currentNcvType" == "${tt[END_NCV]}" ]]; then
                        currentSide=$LEFT_SIDE
                    else
                        currentSide=$RIGHT_SIDE
                    fi
                    tokensInNCV=0
                    wasLeftSideModulus=$FALSE
                    ;;
                [${tt[END_NCV]}${tt[END_CV]}${tt[END_V]}])
                    currentNcvType=""
                    currentSide=""
                    tokensInNCV=""
                    ;;
            esac
            # Copy the NCV delimiter token to the output stream
            streamToken $nextLetter${rhs:2:1}; output+=$g_returnString
            # Advance the input stream past this token
            [[ $rhs =~ ^...(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue

        # Identify left and right parentheses. Track their nesting levels and their types (grouping or functional).
        elif [[ $letter =~ $g_leftParen ]]; then
            ((globalNestingLevel++))

            # If the pending token was marked as a word, it's really a function name and the current parenthesis
            # is a function parenthesis. We modify the token accordingly (in the pending buffer, where it currently
            # resides) and stream it with the function paren.
            if [[ $g_compoundTokenType == ${tt[EXPANDABLE_WORD]} ]]; then
                ((funcNestingLevel++))

                # Mark the pending token as a function name
                g_compoundTokenBuffer=${g_compoundTokenBuffer/$g_compoundTokenType/${tt[FUNCTION]}}
                g_compoundTokenType=${tt[FUNCTION]}

                # Stream the token with the function parenthesis indicator
                streamToken ${tt[BEGIN_FUNCTION]}$globalNestingLevel; output+=$g_returnString

            else
                # If the pending token is not a word, stream it with the grouping parenthesis indicator
                streamToken ${tt[BEGIN_GROUP]}$globalNestingLevel; output+=$g_returnString
            fi

            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue

        elif [[ $letter =~ $g_rightParen ]]; then
            # Assign this ')' the same paren type as its matching '(', which is the nearest one to the left with the same nesting level.
            local parenIndicator=${tt[BEGIN_FUNCTION]}${tt[BEGIN_GROUP]}
            [[ $output =~ .*$tokenDelimiter[0-9]*([$parenIndicator])$globalNestingLevel(.*) ]]
            # Function-type parentheses
            if [[ ${BASH_REMATCH[1]} == ${tt[BEGIN_FUNCTION]} ]]; then
                local tokenToLookFor tokenOccurrences=0 functionArity
                local functionCall=${BASH_REMATCH[2]}

                # Determine the arity of the function call by counting the delimiter tokens at the current (paren) nesting level:
                # (1) Construct the delimiter token we will search for
                tokenToLookFor=$tokenDelimiter"[0-9]+"${tt[DELIMITER]}$globalNestingLevel
                # (2) Count off the commas left-to-right
                while [[ $functionCall =~ ("$tokenToLookFor")(.*) ]]; do
                    ((tokenOccurrences++))
                    functionCall=${BASH_REMATCH[2]}
                done
                if ((tokenOccurrences > 0)); then
                    ((functionArity=tokenOccurrences + 1))
                else
                    [[ -z $functionCall ]]
                    functionArity=$?         # 0 if blank, 1 otherwise
                fi

                # Close the function arg list
                streamToken ${tt[END_FUNCTION]}$globalNestingLevel${tt[FUNCTION_ARITY]}$functionArity; output+=$g_returnString
                ((funcNestingLevel--))
            # Grouping parentheses
            else
                streamToken ${tt[END_GROUP]}$globalNestingLevel; output+=$g_returnString
            fi

            ((globalNestingLevel--))
            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue

        # Identify bit-shift operators and comparators. Since they are similar, just one regex match will do.
        elif [[ $rhs =~ ^([=\<\>\!]{1,2})(.*) ]]; then
            comp=${BASH_REMATCH[1]}
            rhs=${BASH_REMATCH[2]}

            # Tokenize and stream the operator or comparator.
            if [[ $comp == '<<' || $comp == '>>' ]]; then
                streamToken ${tt[OPERATOR]}$comp; output+=$g_returnString
                continue
            else
                # Some lexical analysis: note the transition to the right-hand side of the NCV expression
                currentSide=$RIGHT_SIDE

                streamToken ${tt[COMPARATOR]}$comp; output+=$g_returnString
                continue
            fi

        # Mark boolean logic operators
        elif [[ "$rhs" =~ ^($g_ANDop|$g_ORop)(.*) ]]; then
            rhs=${BASH_REMATCH[2]}
            streamToken ${tt[BOOLEAN]}"$letter"; output+=$g_returnString
            continue

        # TODO Mark isolated (non-list) NULLs. Distinguish them from minus-sign operators...

        # Mark commas as argument delimiters if we are inside a function call or we are not in WHERE-clause mode.
        # In other situations commas are list-item delimiters and should not be marked at all.
        elif [[ $letter == , && ($funcNestingLevel -gt 0 || $isWhereClause == $FALSE) ]]; then
            streamToken ${tt[DELIMITER]}$globalNestingLevel; output+=$g_returnString
            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue
        fi

        #######################################################################################################################
        #
        # Now we look at "string-like" and numeric tokens. In contrast to the above, the process of identifying these tokens correctly
        # depends pretty tightly on their internal structure. We cannot simply look at their first few characters.
        #
        #######################################################################################################################
        #
        # First we process tokens that are, or might be, expandable words (aka abbreviated column/table/function names).
        # These tokens begin with [[:lower:]] or perhaps "*" and are simple alphanumerics, i.e. they are not lists or regexes.
        #
        #######################################################################################################################

        # Identify and extract words that might be expandable. We begin by casting a wide net, snagging all simple values
        # that don't begin with a capital because at this stage we can't know which are truly expandable words.
        if [[ $rhs =~ ^([\*[:lower:]][[:alnum:]]*)(.*) ]]; then        # Words must start in a wordlike way, with star or lowercase
            rawToken=${BASH_REMATCH[1]}
            local tmpRhs=${BASH_REMATCH[2]}
            local nextChar=${tmpRhs:0:1}

            # Non-words that begin like words will squeeze through the above filter. To recognize them, we look at the following
            # character (if there is one). If the supposed word is a true word, then that character is illegal within a word and
            # so it must begin a new token (which cannot be a word). Otherwise, the "word" is not really a word and this character
            # is the continuation of a non-word. Here we check for characters that indicate the latter case obtains. For instance,
            # a quote mark that follows a "word" tells us it was not really a word but the start of a literal value that has yet
            # to terminate. (We include the % sign among these characters on the assumption that it appears as the SQL globbing
            # operator. We have code elsewhere that corrects this assumption if it turns out to be the modulus operator instead.)
            nonwordExtenders=[_%${eitherQuote}]

            if ((funcNestingLevel==0)); then
                # Outside function calls, we interpret commas as delimiters appearing within lists, which are non-word values.
                # These commas serve as extenders of non-word tokens.
                # Inside function calls, the commas always serve as argument delimiters, since we will not encounter lists there.
                # In that context, there are no tokens that can cross comma-delimited boundaries, so commas never act as extenders.
                nonwordExtenders+=,
            fi

            # If the next character is not a "nonword extender", i.e. it serves to terminate an actual word,
            # then process the word as a true word
            if [[ ! $nextChar =~ $nonwordExtenders ]]; then

                # If the word begins with a "*", it is a true word only when the "*" is preceded by another operator
                # or by certain other special characters. Otherwise it is the "times" operator. If it turns out to be
                # the latter, we dump the "*" to the output and continue the main token processing loop
                if [[ ($letter == '*') && -n "$previousLetter" && (! "+-*/ (&|" =~ "$previousLetter") ]]; then
                    streamToken ${tt[OPERATOR]}$letter; output+=$g_returnString
                    rhs=${rhs/#"$letter"}
                    continue

                else
                    # Mark this as a (possible sequence of) expandable words. This enables us to process word sequences
                    # such as "DISTINCT foobar" and "INTERVAL n DAY".
                    bufferToken "$rawToken" ${tt[EXPANDABLE_WORD]}

                    # Proceed to the next token
                    rhs=$tmpRhs
                    continue
                fi
            fi
        fi

        #####################################
        #
        # Next we handle any string-like tokens that are guaranteed not to be expandable words; these are string constants.
        #
        # We break this task down according to the major possibilities:
        # (1) The token starts with a NULL indicator "-,". We make note of the indicator and then look at whatever follows it, as in items (2)-(4).
        # (2) The token starts with a quoted literal: "..." or '...'
        # (3) The "most normal" case: an alnum-type token; this would be either a simple or complex token starting with [[:upper:]_%] or a complex
        # token starting with [[:lower:]].
        # (4) The token starts with a digit sequence but is not a numeric token.
        #
        #####################################

        # (1) If there is a list-initial NULL indicator, flag it and strip it from the input stream
        if [[ $rhs =~ ^-, ]]; then
            rawToken="-,"
            rhs=${rhs:2}
            letter=${rhs:0:1}
        else
            rawToken=""
        fi

        # (2) Stream quoted literals.
        if [[ $letter =~ [${eitherQuote}] ]]; then
            retrieveFullToken
            bufferToken "$rawToken" ${tt[STRING_CONSTANT]}
            continue

        # (3) Stream "normal" alpha-like string tokens.
        # Grab the first part of the token with respect to quotes and NULL markers
        elif [[ $rhs =~ ^([[:alpha:]_%][[:alnum:]_%,]*)(.*) ]]; then
            rawToken+=${BASH_REMATCH[1]}     # Use plus-equals to keep the NULL prefix ("-,") if it's there
            rhs=${BASH_REMATCH[2]}

#TODO Test single-char tokens, esp. "%" which can be the modulus operator or a single-character SQL regex. We'll assume the latter case holds
#TODO if and only if either the NCV or its RHS consists solely of "%".

            # Probe forward across all quoted pieces and embedded NULLs to make sure we have the complete token
            if [[ ($rhs =~ ^[$eitherQuote]) || ($rhs =~ ^- && $rawToken =~ ,$) ]]; then
                letter=${rhs:0:1}

                # The token has additional sub-pieces. Grab the whole token.
                retrieveFullToken
            fi

            # Tokens having a percent sign in the middle need to be "decoded" to be properly understood
            if [[ $rawToken =~ % ]]; then
                processPercentSignToken "$rawToken" $currentSide $wasLeftSideModulus
                wasLeftSideModulus=$?
                continue
            # Normal tokens can be buffered as-is
            else
                bufferToken "$rawToken" ${tt[STRING_CONSTANT]}
                continue
            fi

        # (4) We stream digit-initial alnums that are not numbers per se. When inside a function call,
        # we must tokenize differently because commas play a different role. We handle that elsewhere.

        # Get the first part consisting of alnums, commas, and regexes only.
        elif [[ ($funcNestingLevel -eq 0) && $rhs =~ ^([0-9][[:alnum:]%_,]+)(.*) ]]; then
            local tmpToken=${BASH_REMATCH[1]}
            local tmpRhs=${BASH_REMATCH[2]}

            # Only proceed if the first part has something non-digital.
            if [[ $tmpToken =~ [^[:digit:]] ]]; then
                # Strip off the leading part
                rawToken+=$tmpToken
                rhs=$tmpRhs

                # Probe forward across all quoted or NULL parts to get the complete token
                if [[ ($rhs =~ ^[$eitherQuote]) || ($rhs =~ ^- && $rawToken =~ ,$) ]]; then
                    letter=${rhs:0:1}

                    retrieveFullToken
                fi

                # Tokens having a percent sign in the middle need to be "decoded" to be properly understood
                if [[ $rawToken =~ % ]]; then
                    processPercentSignToken "$rawToken" $currentSide $wasLeftSideModulus
                    wasLeftSideModulus=$?
                    continue
                # Normal tokens can be buffered as-is
                else
                    bufferToken "$rawToken" ${tt[STRING_CONSTANT]}
                    continue
                fi
            fi
        fi

        # Numeric- and date-like values
        if [[ $rhs =~ ^([-]?([0-9]*\.)?[0-9]+)(.*) ]]; then      # will capture the leading int or float of numeric/date-like values
            local oldRhs=$rhs
            local value=${BASH_REMATCH[1]}
            rhs=${BASH_REMATCH[3]}

            # First character beyond the initial number tells us a lot about the full extent of the value
            local nextChar=${rhs:0:1}
            local following ending

            case $nextChar in
              ,) # function argument or numeric list
                if ((funcNestingLevel > 0)); then
                    streamToken ${tt[NUMERIC]}$value; output+=$g_returnString
                else
                    [[ $rhs =~ ^$nextChar([-0-9,.]+)(.*) ]]    # NOTE: We could specify more precisely where negative signs may be placed
                    value+=$nextChar${BASH_REMATCH[1]}
                    rhs=${BASH_REMATCH[2]}
                    if [[ $value =~ \. ]]; then
                        streamToken ${tt[FLOATLIST]}$value; output+=$g_returnString
                    else
                        streamToken ${tt[INTLIST]}$value; output+=$g_returnString
                    fi
                fi
                ;;
              /) # date, date range, or division operator (TODO timestamps)
                local followingPart startingDate
                # First we deal with tokens that begin yyyy/mm/dd
                if [[ $oldRhs =~ ([0-9]{4}/[0-9]{1,2}/[0-9]{1,2})(.*) ]]; then
                    # Starts with a full date (yyyy/mm/dd). Discriminate between dates, date ranges and date subtractions
                    startingDate=${BASH_REMATCH[1]}
                    followingPart=${BASH_REMATCH[2]}

                    # Minus sign after date means it's either a date range or a numeric-from-date subtraction.
                    if [[ $followingPart =~ ^- ]]; then
                        # We will always choose the date-range interpretation when both are valid. Alternatively,
                        # the user can force the latter by inserting space delimiters in the input.

                        # Grab the numeric-or-date part after the minus sign
                        [[ $followingPart =~ ^(-[/0-9]+)(.*) ]]
                        followingPart=${BASH_REMATCH[1]}
                        rhs=${BASH_REMATCH[2]}

                        # A slash therein indicates a date range; stream it as such
                        if [[ $followingPart =~ / ]]; then
                            value=$startingDate$followingPart
                            streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString

                        # No slash; only digits means we must decide: date range or date subtraction?
                        elif [[ $followingPart =~ [0-9] ]]; then
                            # We analyze the numbers surrounding the minus sign
                            local number1=${startingDate##*/}
                            local number2=${followingPart#-}
                            if ((number2<=31 && number2>number1)); then
                                # Treat it as a date range
                                value=$startingDate$followingPart
                                streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                            else
                                # Treat it as a date subtraction. Create three tokens.
                                value=$startingDate
                                streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                                streamToken ${tt[OPERATOR]}-; output+=$g_returnString
                                streamToken ${tt[STRING_CONSTANT]}$number2; output+=$g_returnString
                            fi
                        # other stuff after minus sign --> error
                        else
                            echo Invalid date expression. > /dev/stderr
                            return 2
                        fi
                    else
                        # No trailing minus sign. It's a plain old date.
                        value=$startingDate$followingPart
                        rhs=$followingPart
                        streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                    fi
                # Now we deal with tokens that begin yyyy/mm. We interpret these as either date ranges or arithmetic. (Is that the best way?)
                elif [[ $oldRhs =~ ([0-9]{4}/[0-9]{1,2})(.*) ]]; then
                    startingDate=${BASH_REMATCH[1]}
                    followingPart=${BASH_REMATCH[2]}
                    if [[ $followingPart =~ ^- ]]; then
                        # Grab the date part after the minus sign
                        [[ $followingPart =~ ^(-[/0-9]+)(.*) ]]
                        followingPart=${BASH_REMATCH[1]}
                        rhs=${BASH_REMATCH[2]}
                        value=$startingDate$followingPart
                        streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                    else
                        # Treat it as arithmetic.
                        rhs=$followingPart
                        streamToken ${tt[STRING_CONSTANT]}${startingDate:0:4}; output+=$g_returnString
                        streamToken ${tt[OPERATOR]}'/'; output+=$g_returnString
                        streamToken ${tt[STRING_CONSTANT]}${startingDate:5}; output+=$g_returnString
                    fi
                # Finally we deal with other tokens, where the successive runs of digits do NOT suggest a date. We treat it as arithmetic.
                else
                    # (Merge with the code immediately above!)
                    rhs=$followingPart
                    streamToken ${tt[STRING_CONSTANT]}${startingDate:0:4}; output+=$g_returnString
                    streamToken ${tt[OPERATOR]}'/'; output+=$g_returnString
                    streamToken ${tt[STRING_CONSTANT]}${startingDate:5}; output+=$g_returnString
                fi
                # This concludes the '/' processing.
                ;;
              :) # prefix list
                 #TODO Accommodate a range set (in the future), whose rhs would be approximately ^:[0-9,:;-]+
                [[ $rhs =~ ^$nextChar([0-9,]+)(.*) ]]
                value+=$nextChar${BASH_REMATCH[1]}
                rhs=${BASH_REMATCH[2]}
                streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                ;;
              -) # date, numeric range or subtraction operator
                oldRhs=$rhs
                # Check for a date.
                if [[ $oldRhs =~ ([0-9]{4}-[0-9]{1,2}-[0-9]{1,2})(.*) ]]; then
                    value=${BASH_REMATCH[1]}
                    rhs=${BASH_REMATCH[2]}
                    streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                else
                    # Not a date. Either a numeric range or arithmetic.
                    #TODO Recognize solitary NULLs
                    [[ $rhs =~ ^$nextChar([0-9]*)(.*) ]]
                    following=${BASH_REMATCH[1]}
                    ending=${BASH_REMATCH[2]}
                    if [[ -n $following ]]; then
                        # There are some following digits. In deciding what to do, we venture into semantic analysis to observe that
                        # a numeric range is only valid when it occurs as the sole token after a comparator (in the given NCV construct).
                        # We assume that it's not an integer subtraction, by the "Contrapositive of Occam's razor" discussed elsewhere.
                        # The logic: if "nothing ahead, i.e. empty or closeParen" and "comparator-or-nothing behind" ...
                        if [[ (-z $ending || "$ending" =~ ^\ ?$g_rightParen) && ($output =~ ([\<\>=]|${tt[BEGIN_NCV]}[0-9]+${tokenDelimiter})$) ]]; then
                            # numeric range
                            value+=$nextChar$following
                            rhs=$ending
                            streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                        else
                            # arithmetic subtraction     # TODO What about arithmetic negation?
                            rhs=$following$ending    # remove leading minus sign
                            streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                            streamToken ${tt[OPERATOR]}'-'; output+=$g_returnString
                        fi
                    else
                        # There are no following digits (perhaps a name/word follows)
                        rhs=$following$ending
                        streamToken ${tt[STRING_CONSTANT]}$value; output+=$g_returnString
                        streamToken ${tt[OPERATOR]}'-'; output+=$g_returnString
                    fi
                fi
                ;;
              *) # Anything else means it is a single int or float. Buffer it because it could turn out to be a "123 Main St".
                bufferToken "$value" ${tt[NUMERIC]} 
                ;;
            esac
            continue

        # '@'-delimited filenames
        elif [[ $rhs =~ ^@([^@]*)@(.*) ]]; then
            fileName=${BASH_REMATCH[1]}
            rhs=${BASH_REMATCH[2]}
            streamToken ${tt[FILENAME]}"$fileName"; output+=$g_returnString
            continue

        # $-marked variables. The intention: Force them to be expanded to a name.
        elif [[ "$rhs" =~ ^\$([*a-z][[:alnum:]]*)(.*) ]]; then
            local value=${BASH_REMATCH[1]}
            rhs=${BASH_REMATCH[2]}
            streamToken ${tt[FORCED_EXPANSION]}$value; output+=$g_returnString
            continue

        # Single-character operators
        # TODO Make this list exhaustive. Make sure alternate meanings of these characters are ruled out before this point.
        elif [[ $letter =~ [-+*/%^\&|] ]]; then
            streamToken ${tt[OPERATOR]}$letter; output+=$g_returnString
            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue

        # Markup spaces with a special descriptor
        elif [[ $letter =~ [\ ] ]]; then

            # Advance through the input stream
            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}

            # Normally we stream a space token immediately...
            if [[ -z $g_compoundTokenBuffer ]]; then
                # Use streamToken() to delimit the space from whatever precedes it. A raw space is incorrect.
                streamToken ${tt[SPACE]}; output+=$g_returnString
            # ...but if we are inside a space-containing ("compound") value, we add it raw to the value buffer
            else
                bufferSpace
            fi

            continue

        # Any material not caught by the above is copied raw. TODO Make sure this doesn't happen!
        else
            output+=$letter
            [[ $rhs =~ ^"$letter"(.*) ]]
            rhs=${BASH_REMATCH[1]}
            continue
        fi

    done

    if ((globalNestingLevel!=0)); then
        echo Parsing error: Unbalanced parentheses in argument "$1". > /dev/stderr
        return 1
    fi

    # Don't fall off the end of the input without flushing the buffer.
    if [[ -n $g_compoundTokenBuffer ]]; then
        streamToken; output+=$g_returnString   # Invoke with no arguments to force a buffer flush only.
    fi

    g_returnString=$output
    return 0
}


##################################################################################################
# processPercentSignToken()
#
# A string consisting of one "%" surrounded by the right kind of text could be parsed as two kinds of operations:
# either a glob OR a modulus, e.g. "foo%5" could mean either 'foo%5' OR foo % 5. We can tell the difference
# by whether the string is on the right or left hand side of the current NCV.
##################################################################################################
function processPercentSignToken()
{
    local rawToken="$1" side=$2 wasLeftModulus=$3
    if [[ $rawToken =~ ([^%]*)%([^%]*) ]]; then
        local leftSide=${BASH_REMATCH[1]}
        local rightSide=${BASH_REMATCH[2]}
        local tokenType

        if [[ $side == $LEFT_SIDE || $wasLeftModulus ]]; then
            # Interpret as 3 tokens: the left side, % as modulus operator, and the right side
            if [[ $leftSide =~ ^[\*[:lower:]][[:alnum:]]*$ ]]; then
                tokenType=${tt[EXPANDABLE_WORD]}
            else
                tokenType=${tt[STRING_CONSTANT]}
            fi
            streamToken $tokenType$leftSide; output+=$g_returnString

            streamToken ${tt[OPERATOR]}%; output+=$g_returnString

            if [[ $rightSide =~ ^[\*[:lower:]][[:alnum:]]$ ]]; then
                tokenType=${tt[EXPANDABLE_WORD]}
            else
                tokenType=${tt[STRING_CONSTANT]}
            fi
            streamToken $tokenType$rightSide; output+=$g_returnString

            wasLeftModulus=$TRUE
            continue
        else
            # Interpret the % sign as the globbing operator, streaming the entire rawToken as a single token.
            bufferToken "$rawToken" ${tt[STRING_CONSTANT]}
            continue
        fi
    fi

    return $wasLeftModulus
}


####################################################################################
# delimitNCVsInString
# 
# Insert NCV delimiter markers in the data stream which also indicate the type of NCV:
# NCV, CV or V.
####################################################################################
function delimitNCVsInString()
{
    local remainingInput=$1 newString=""
    local workNCV operator
    local ncvCount=0

    while [[ -n $remainingInput ]]; do
        # Process one NCV at a time
        if [[ "$remainingInput" =~ ([\ ]*($g_ANDop|$g_ORop)[\ ]*)(.*) ]]; then
            workNCV=${remainingInput%${BASH_REMATCH[0]}}
            operator=${BASH_REMATCH[2]}
            remainingInput=${BASH_REMATCH[3]}
        else
            workNCV=$remainingInput
            operator=""
            remainingInput=""
        fi

        # Figure out the parenthesis imbalance in the working NCV
        local workNCV2=$workNCV   # set up a temp copy that we can mangle
        declare -i parenBalance=0
        while [[ "$workNCV2" =~ ($g_leftParen|$g_rightParen)(.*) ]]; do
            workNCV2=${BASH_REMATCH[2]}
            if [[ "${BASH_REMATCH[1]}" =~ $g_leftParen ]]; then
                ((parenBalance++))
            else
                ((parenBalance--))
            fi
        done 

        # Trim the working NCV to achieve parenthesis balance
        workNCV2=$workNCV    # fetch the unaltered NCV
        local leftSide="" rightSide=""
        while ((parenBalance > 0)); do
            # Remove excess left-parens
            [[ $workNCV2 =~ ^([ ]*${g_leftParen}[ ]*)(.*) ]]
            leftSide+=${BASH_REMATCH[1]}
            workNCV2=${BASH_REMATCH[2]}
            ((parenBalance--))
        done
        while ((parenBalance < 0)); do
            # Remove excess right-parens
            [[ $workNCV2 =~ (.*)([ ]*${g_rightParen}[ ]*)$ ]]
            rightSide=${BASH_REMATCH[2]}$rightSide
            workNCV2=${BASH_REMATCH[1]}
            ((parenBalance++))
        done

        # Trim the working NCV to remove superfluous parenthesis pairs
        while [[ $workNCV2 =~ ^([ ]*${g_leftParen}[ ]*)(.*) ]]; do
            br1=${BASH_REMATCH[1]}
            if [[ $workNCV2 =~ (.*)([ ]*${g_rightParen}[ ]*)$ ]]; then
                leftSide+=$br1
                rightSide=${BASH_REMATCH[2]}$rightSide
                workNCV2=${BASH_REMATCH[1]#$br1}
            else
                break
            fi
        done

        # Patch together the trimmed parts with the appropriate NCV delimiters
        # to build the new, ncv-delimited string

        # Set the NCV-beginning delimiter
        tokensInNCV=""
        streamToken ${tt[BEGIN_NCV]}$((++ncvCount)); beginDelimiter=$g_returnString

        # Select the NCV-ending delimiter for the NCV type
        local ncvType
        if [[ ! "$workNCV2" =~ ([^=\<\!\>]*)([=\<\!\>]+)(.*) ]]; then
            # Match failed because there is no comparator
            ncvType=${tt[END_V]}
        elif [[ -n ${BASH_REMATCH[1]} ]]; then
            # Comparator is preceded by some text
            ncvType=${tt[END_NCV]}
        else
            # Comparator is all the way at the beginning
            ncvType=${tt[END_CV]}
        fi
        streamToken $ncvType$ncvCount; endDelimiter=$g_returnString

        newString+=$leftSide$beginDelimiter$workNCV2$endDelimiter$rightSide
        newString+=$operator
    done

    g_returnString=$newString
}

####################################################################################
# retrieveFullToken
#
# Given a value token of string-like type, advance the lexer through all adjacent pieces of quoted
# and non-quoted text in order to obtain the complete token
####################################################################################
function retrieveFullToken()
{
    while ((1)); do

        # Handle the present "feature" in the token: an embedded NULL indicator, a quoted piece or an orphaned quote character

        # Check for embedded NULL
        if [[ ($rhs =~ ^-) && ($rawToken =~ ,$) ]]; then
            # Append it, leaving the following comma in place if there is one.
            rawToken+="-"
            rhs=${rhs:1}

        # Check for a quoted literal: match the quote to its companion
        elif [[ $rhs =~ ^${letter}([^${letter}]*)${letter}(.*) ]]; then
            rawToken+=${BASH_REMATCH[1]}    # Strip off the surrounding quotes before tokenizing.
            rhs=${BASH_REMATCH[2]}

        # Otherwise assume we have an orphaned " or ' character. Peel it off.
        else
            rawToken+=$letter
            rhs=${rhs:1}
        fi

        # Check the termination conditions
        if [[ ! $rhs =~ ^[[:alnum:],_%] ]]; then
            break
        fi

        # If not terminated, advance through the following "featureless" part of the token
        [[ $rhs =~ ^([[:alnum:],_%]+)(.*) ]]
        rawToken+=${BASH_REMATCH[1]}
        rhs=${BASH_REMATCH[2]}

        # Check the termination conditions
        letter=${rhs:0:1}
        if [[ ! $letter =~ [-${eitherQuote}] ]]; then
            break
        fi
    done
}


####################################################################################
# convertEscapeSequences
#
# There are two ways to insert special characters as literals: quoting them (individually or in context),
# and backslash-escaping them. Here we eliminate backslash escapes so the parser only needs to manage
# the former. We convert the C-style escape symbols to their underlying values (for instance, backslash-en
# becomes literal newline) and for other escaped characters we change the backslash to a pair of quotes.
####################################################################################
function convertEscapeSequences()
{
    local workString=$1

    while [[ $workString =~ $g_escapeChar(.) ]]; do

        # Extract the special character and choose a quoting character.
        local specialChar=${BASH_REMATCH[1]} quoteChar="'"
        if [[ $specialChar == "'" ]]; then quoteChar='"'; fi

        # Determine the replacement text.
        case $specialChar in
            n) replacement=$'\n' ;;
            t) replacement=$'\t' ;;
            r) replacement=$'\r' ;;
            f) replacement=$'\f' ;;
            v) replacement=$'\v' ;;
            b) replacement=$'\b' ;;
            [%_]) replacement="\\"$specialChar ;;     # Retain the backslash.  # TODO The SQL generator needs to add a trailing subclause of "ESCAPE '\'"
                # TODO Both of these character pairs \[%_] can also mess up the parsing below. Change the parser to fix this.
            # All other escaped characters will be admitted as literals
                # TODO Literal single quotes should be represented in SQL as '' (quote-pairs)
            *) replacement=${BASH_REMATCH[1]} ;;
        esac

        # Surround the replacement text with quotes
        workString=${workString/$g_escapeChar$specialChar/$quoteChar$replacement$quoteChar}
    done

    g_returnString=$workString
}

################################################################################
# streamToken  token  [...]
#
# Adds a sequence of marked-up tokens to the token stream, first checking whether
# there is a pending buffer that needs to be flushed to the stream.
# Without arguments, will simply flush the pending buffer to the stream.
#
# Also tracks the prior token for (future) use in subsequent parsing logic.
#
# TODO Factor out the markup to a separate argument, giving the following syntax:
#       streamToken markup token [...]
################################################################################
function streamToken()
{
    g_returnString=""

    # If there is a complete value sitting in the buffer, then we flush it to the token stream.
    if [[ -n $g_compoundTokenBuffer ]]; then
        local needTrailingSpace=$FALSE

        # Flushing the buffer to the stream consists of 4 steps.

        # 1. The buffer builder prefetches trailing spaces as it builds up the compound value,
        # so it might terminate with a superfluous space. If so, pull it off, append the buffered
        # value, and then append a space token (not a raw space).
        if [[ $g_compoundTokenBuffer =~ (.*)" "$ ]]; then
            g_compoundTokenBuffer=${BASH_REMATCH[1]}
            needTrailingSpace=$TRUE      # add the space token in just a moment
        fi

        # 2. Append the buffered token.
        output+=$g_compoundTokenBuffer

        # 3. Empty the buffer
        g_compoundTokenBuffer=""
        g_compoundTokenType=""

        # 4. If required by step 1, add a space token to the stream.
        if ((needTrailingSpace)); then
            streamToken ${tt[SPACE]}; output+=$g_returnString
            g_returnString=""
        fi
    fi

    # Append the supplied token(s) to the stream and do some bookkeeping
    while [[ -n $1 ]]; do
        g_prevToken=$g_currToken
        g_currToken=$1
        g_returnString+=$tokenDelimiter$tokensInNCV$1
        if [[ -n $tokensInNCV ]]; then
            ((tokensInNCV++))
        fi
        shift
    done
}


###############################################################################
# bufferToken  <newToken>  <newTokenType>
# bufferSpace  (no arguments)
#
# Variants of streamToken for use with constant-string values and word sequences.
# The value is grown inside a buffer so that the complete value can be appended
# to the stream as a single token once we have the complete token.
#
# This technique allows us to accommodate unprotected, unescaped spaces
# in these contexts. This is a workaround to our normal process in which
# we always treat naked spaces as token delimiters,
###############################################################################
function bufferToken()
{
    local newToken=$1
    local newTokenType=$2
    local initialTokenType=$g_compoundTokenType

    # Two steps: (1) Set or reset the token type (2) Append the token piece to the buffer

    # The specifics of step (1) depend on whether the buffer is currently empty.
    # If the buffer is empty, just set the token type
    if [[ -z $g_compoundTokenBuffer ]]; then
        g_compoundTokenType=$newTokenType
        : ${tokensInNCV:=0}
        g_compoundTokenBuffer=${tokenDelimiter}${tokensInNCV}$newTokenType
        ((tokensInNCV++))

    # If the buffer is not empty, the fact that we've returned to this code proves the token is compound.
    # We carefully update our guess as to the token type.
    else

        # Expandable-word indicators go stale once we've determined the token is compound,
        # so change them appropriately.
        if [[ $initialTokenType == ${tt[EXPANDABLE_WORD]} ]]; then

            # A word appended to another word is promoted to a word sequence
            if [[ $newTokenType == ${tt[EXPANDABLE_WORD]} ]]; then
                updateCompoundTokenType ${tt[EXPANDABLE_SEQUENCE]}

            # Anything else would make this a string literal
            else
                updateCompoundTokenType ${tt[STRING_CONSTANT]}
            fi

        # A word sequence is promoted to a string literal if the new token piece is not a word
        elif [[ $initialTokenType == ${tt[EXPANDABLE_SEQUENCE]} ]]; then

            # The type remains word-sequence if the new piece is a word
            if [[ $newTokenType == ${tt[EXPANDABLE_WORD]} ]]; then
                :

            # Otherwise the token is revealed to be a string literal
            else
                updateCompoundTokenType ${tt[STRING_CONSTANT]}
            fi

        # Anything else is a string literal (only literal-likes (true literals, ints, floats, etc.) should get here)
        else
            updateCompoundTokenType ${tt[STRING_CONSTANT]}
        fi
    fi

    # Step (2): In all cases, add the new token to the buffer
    g_compoundTokenBuffer+=$newToken
}

function bufferSpace()
{
    g_compoundTokenBuffer+=" "
}


#####
# updateCompoundTokenType  <newType>
# helper function for bufferToken
#####
function updateCompoundTokenType()
{
    local initialTokenType
    [[ $g_compoundTokenBuffer =~ ^.[0-9]+(.) ]]
    initialTokenType=${BASH_REMATCH[1]}

    # Update the standalone value type and its place in the buffer
    g_compoundTokenType=$1
    g_compoundTokenBuffer=${g_compoundTokenBuffer/$initialTokenType/$g_compoundTokenType}
}

